{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-brsVDBz7GS",
        "outputId": "ce07d728-1295-4ee2-8069-7fc0e6d70ab6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python3-mysqldb is already the newest version (1.3.10-1build1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 20 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: geopy in /usr/local/lib/python3.8/dist-packages (1.17.0)\n",
            "Requirement already satisfied: geographiclib<2,>=1.49 in /usr/local/lib/python3.8/dist-packages (from geopy) (1.52)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kmodes in /usr/local/lib/python3.8/dist-packages (0.12.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.8/dist-packages (from kmodes) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from kmodes) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.8/dist-packages (from kmodes) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.8/dist-packages (from kmodes) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22.0->kmodes) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!sudo apt-get install python3-dev libmysqlclient-dev > /dev/null\n",
        "!pip install mysqlclient > /dev/null\n",
        "!sudo pip3 install -U sql_magic > /dev/null\n",
        "!pip install psycopg2-binary  > /dev/null\n",
        "!pip install -q geopandas sqlalchemy\n",
        "!apt-get install python3-mysqldb\n",
        "!pip install geopy\n",
        "!pip install kmodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5HSM2NsCkzua"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9SIZrumPk-X5"
      },
      "outputs": [],
      "source": [
        "# Install the SQLAlchemy library if it is not installed\n",
        "# !sudo apt-get install python3-dev libmysqlclient-dev > /dev/null\n",
        "# !pip install mysqlclient > /dev/null\n",
        "# !sudo pip3 install -U sql_magic > /dev/null\n",
        "# !pip install psycopg2-binary > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixkuXPdAmuMI",
        "outputId": "f8f044f7-a965-495d-c839-709b9a10f5fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "app.py\tnode_modules  nohup.out  package-lock.json  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaT9uw0y1BKF",
        "outputId": "940faded-6040-4761-e6be-2e1a488f5d45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from kmodes.kmodes import KModes\n",
        "import matplotlib.pyplot as plt\n",
        "from sqlalchemy import create_engine\n",
        "import requests\n",
        "import datetime\n",
        "from bs4 import BeautifulSoup\n",
        "from geopy.geocoders import Nominatim\n",
        "import geopandas as gpd\n",
        "\n",
        "conn_string = 'mysql://{user}:{password}@{host}:{port}/{db}?charset=utf8'.format(\n",
        "  user='Non-Trivial', \n",
        "  password='N14GUb5l9B8=', \n",
        "  host = 'jsedocc7.scrc.nyu.edu', \n",
        "  port     = 3306, \n",
        "  encoding = 'utf-8',\n",
        "  db = 'Non-Trivial'\n",
        ")\n",
        "engine = create_engine(conn_string)\n",
        "\n",
        "def populate(df, column):\n",
        "  genres = df[column].tolist()\n",
        "  uniqueGenres = []\n",
        "  for i in genres:\n",
        "    for j in i.split(','):\n",
        "      if j not in uniqueGenres:\n",
        "        uniqueGenres.append(j.strip(\"' []\"))\n",
        "\n",
        "  foo = []\n",
        "  for k in uniqueGenres:\n",
        "    bar = []\n",
        "    for l in range(0,len(df)):\n",
        "      if k in df[column].iloc[l]:\n",
        "        bar.append(1)\n",
        "      else:\n",
        "        bar.append(0)\n",
        "    foo.append(bar)\n",
        "\n",
        "  count = 0\n",
        "  for i in uniqueGenres:\n",
        "    df[i] = foo[count]\n",
        "    count += 1\n",
        "\n",
        "def cluster(df,num,column):\n",
        "  kmode = KModes(n_clusters=num, init = \"random\", n_init = 5, verbose=1)\n",
        "  clusters = kmode.fit_predict(df.iloc[:,column:])\n",
        "  df.insert(0, \"Cluster\", clusters, True)\n",
        "\n",
        "def findCategory(pivot, category):\n",
        "  return pivot.idxmax(axis = 1)[category]\n",
        "\n",
        "streaming_df = pd.read_sql_table(\"imdbStreaming\", conn_string)\n",
        "populate(streaming_df,\"Genre\")\n",
        "cluster(streaming_df,15,5)\n",
        "\n",
        "yelp_df = pd.read_sql_table(\"expandedYelp\", conn_string)\n",
        "populate(yelp_df,\"food\")\n",
        "cluster(yelp_df,15,19)\n",
        "\n",
        "clusteredStreaming = streaming_df.groupby(['Cluster']).sum().T.iloc[2:-1]\n",
        "clusteredFood = yelp_df.groupby(['Cluster']).sum().T.iloc[6:]\n",
        "\n",
        "header = st.container()\n",
        "userInput = st.container()\n",
        "visualization = st.container()\n",
        "\n",
        "\n",
        "with header:\n",
        "  st.title('What to Do in NYC')\n",
        "\n",
        "with userInput:\n",
        "  #sel_col, disp_col = st.columns(2)\n",
        "  st.header('Enter Your Preferences')\n",
        "\n",
        "  st.text('Movie Preferences')\n",
        "  mpref1 = st.slider('Horror', min_value = 1.0, max_value = 10.0, step = 0.1)\n",
        "  mpref2 = st.slider('Action', min_value = 1.0, max_value = 10.0, step = 0.1)\n",
        "  mpref3 = st.slider('Comedy', min_value = 1.0, max_value = 10.0, step = 0.1)\n",
        "  mpref4 = st.slider('Thriller', min_value = 1.0, max_value = 10.0, step = 0.1)\n",
        "  mpref5 = st.slider('Romance', min_value = 1.0, max_value = 10.0, step = 0.1)\n",
        "  mpref6 = st.slider('SciFi', min_value = 1.0, max_value = 10.0, step = 0.1)\n",
        "  mpref7 = st.slider('Fantasy', min_value = 1.0, max_value = 10.0, step = 0.1)\n",
        "\n",
        "  movie = {'Horror':mpref1, 'Action':mpref2, 'Comedy':mpref3, 'Thriller':mpref4, 'Romance':mpref5, 'Sci-Fi':mpref6, 'Fantasy':mpref7}\n",
        "\n",
        "  st.text('Cuisine Preferences')\n",
        "  fpref1 = st.slider('Italian', min_value = 1.0, max_value = 10.0, step = 0.1)\n",
        "  fpref2 = st.slider('Mediterranean', min_value = 1.0, max_value = 10.0, step = 0.1)\n",
        "  fpref3 = st.slider('Chinese', min_value = 1.0, max_value = 10.0, step = 0.1)\n",
        "  fpref4 = st.slider('American', min_value = 1.0, max_value = 10.0, step = 0.1)\n",
        "  fpref5 = st.slider('Korean', min_value = 1.0, max_value = 10.0, step = 0.1)\n",
        "  fpref6 = st.slider('Latin', min_value = 1.0, max_value = 10.0, step = 0.1)\n",
        "\n",
        "  food = {'italian':fpref1, 'mediterranean':fpref2, 'chinese':fpref3, 'newamerican':fpref4, 'korean':fpref5, 'latin':fpref6}\n",
        "\n",
        "  User_Preferences = {'Movies':movie, 'Food':food, 'User Zipcode': 10003}\n",
        "\n",
        "  @st.cache\n",
        "  def topGenre():\n",
        "    maxMovieScore = 0\n",
        "    maxMovieGenre = \"\"\n",
        "    for i in movie:\n",
        "      if movie[i]>maxMovieScore:\n",
        "        maxMovieScore = movie[i]\n",
        "        maxMovieGenre = i\n",
        "    return maxMovieGenre\n",
        "\n",
        "  @st.cache\n",
        "  def topCuisine():\n",
        "    maxCuisineScore = 0\n",
        "    maxCuisineType = \"\"\n",
        "    for i in food:\n",
        "      if food[i]>maxCuisineScore:\n",
        "        maxCuisineScore = food[i]\n",
        "        maxCuisineType = i\n",
        "    return maxCuisineType\n",
        "\n",
        "  geolocator = Nominatim(user_agent=\"ProjectsinProgramming\")\n",
        "  def findcoordinate(name):\n",
        "    try:\n",
        "      location = geolocator.geocode(name + \" NYC\")\n",
        "      return location.latitude, location.longitude\n",
        "    except:\n",
        "      return None, None\n",
        "\n",
        "  st.header(\"Click update to see recommendations based on your preferences!\")\n",
        "  if st.button('Update'):\n",
        "    maxMovieGenre = topGenre()\n",
        "    maxCuisineType = topCuisine()\n",
        "    \n",
        "    NumRecs = 3\n",
        "\n",
        "    foodFilter = yelp_df[\"Cluster\"] == findCategory(clusteredFood,maxCuisineType)\n",
        "    userScoresFood = []\n",
        "    for j in range(len(yelp_df)):\n",
        "      userScore = 0\n",
        "      for i in food:\n",
        "        if (int(yelp_df.iloc[[j]][i].values[0])==1):\n",
        "          userScore += food[i]\n",
        "      userScore += yelp_df.iloc[[j]][\"rating\"].values[0]\n",
        "      userScoresFood.append(userScore)\n",
        "    yelp_df[\"User Score\"] = userScoresFood\n",
        "    sortedFoodCluster = yelp_df[foodFilter].sort_values(by=['User Score'], ascending=False)\n",
        "\n",
        "    new = {'longitude': [], 'latitude': [],'Name': []}\n",
        "    for i in range (0, NumRecs):\n",
        "      try:\n",
        "        st.text(\"Here's a restaurant that you would like: \" + sortedFoodCluster.iloc[[i]]['name'].values[0])\n",
        "        new['latitude'].append(sortedFoodCluster.iloc[i]['coordinates.latitude'])\n",
        "        new['longitude'].append(sortedFoodCluster.iloc[i]['coordinates.longitude'])\n",
        "        new['Name'].append(sortedFoodCluster.iloc[i]['name'])\n",
        "      except:\n",
        "        continue\n",
        "\n",
        "      key = 'c68ma4janrpjmzkxxz4u9fs7'\n",
        "      date = str(datetime.date.today()) #\"2022-05-06\"\n",
        "      zip = str(sortedFoodCluster.iloc[[i]]['location.zip_code'].values[0])\n",
        "      url = \"http://data.tmsapi.com/v1.1/movies/showings?startDate=\" + date + \"&zip=\" + zip + \"&api_key=\" + key\n",
        "      resp = requests.get(url)\n",
        "      data = resp.json()\n",
        "      df = pd.json_normalize(data)\n",
        "      theater_df = df[[\"tmsId\", \"rootId\", \"subType\", \"title\", \"releaseYear\", \"releaseDate\", \"genres\", \"longDescription\", \"shortDescription\", \"ratings\", \"runTime\", \"showtimes\"]]\n",
        "      list_codes = []\n",
        "      for j in theater_df['ratings']:\n",
        "        try:\n",
        "          list_codes.append(j[0]['code'])\n",
        "        except:\n",
        "          list_codes.append(\"N/A\")\n",
        "      theater_df[\"rating\"] = list_codes\n",
        "      theater_df.drop('ratings', inplace=True, axis=1)\n",
        "      theater_df['genres'] = theater_df['genres'].astype(str)\n",
        "      resp = requests.get(\"https://www.imdb.com/showtimes/location/US/\" + zip)\n",
        "      soup = BeautifulSoup(resp.text)\n",
        "      movies = soup.find_all(\"div\", {'class':'lister-item mode-grid'})\n",
        "      ratings = []\n",
        "      for k,row in theater_df.iterrows():\n",
        "        count = 0\n",
        "        for movie in movies:\n",
        "          if theater_df['title'].iloc[k] == movie.find('div', {'class': 'title'}).text:\n",
        "            if movie.find('div',{'class':'inline-block ratings-imdb-rating'})== None:\n",
        "              cool = 0\n",
        "            else:  \n",
        "              ratings.append(movie.find('div',{'class':'inline-block ratings-imdb-rating'}).text.strip())\n",
        "              count += 1 \n",
        "        if count == 0:\n",
        "          ratings.append(None)\n",
        "      theater_df.insert(12, 'ratings', ratings)\n",
        "      theater_df['ratings'].astype(float)\n",
        "      populate(theater_df,\"genres\")\n",
        "      cluster(theater_df,10,13)\n",
        "      theater_df.rename(columns = {'Science fiction':'Sci-Fi'}, inplace = True)\n",
        "      clusteredTheater = theater_df.groupby(['Cluster']).sum().T.iloc[1:]\n",
        "\n",
        "      theaterFilter = theater_df[\"Cluster\"] == findCategory(clusteredTheater,maxMovieGenre)\n",
        "      userScoresTheater = []\n",
        "      for m in range(len(theater_df)):\n",
        "          userScore = 0\n",
        "          for n in User_Preferences[\"Movies\"]:\n",
        "            if (theater_df.iloc[[m]][n].values[0]==1):\n",
        "              userScore += User_Preferences[\"Movies\"][n]\n",
        "          try:\n",
        "            userScore += theater_df.iloc[[m]][\"ratings\"].values[0]\n",
        "          except:\n",
        "            userScore += 0\n",
        "          userScoresTheater.append(userScore)\n",
        "      theater_df[\"User Score\"] = userScoresTheater\n",
        "      sortedTheaterCluster = theater_df[theaterFilter].sort_values(by=['User Score'], ascending=False)\n",
        "      \n",
        "      for l in range (0, NumRecs):\n",
        "        theaterList = sortedTheaterCluster.iloc[[i]][\"showtimes\"].tolist()\n",
        "        try:\n",
        "          st.text(\"You can catch \" + sortedTheaterCluster.iloc[[l]]['title'].values[0] + \" at \" + theaterList[0][0][\"theatre\"][\"name\"] + \" near \" + sortedFoodCluster.iloc[[i]]['name'].values[0])\n",
        "          latTheater, longTheater = findcoordinate(theaterList[0][0][\"theatre\"][\"name\"])\n",
        "          new['latitude'].append(latTheater)\n",
        "          new['longitude'].append(longTheater)\n",
        "          new['Name'].append(theaterList[0][0][\"theatre\"][\"name\"])\n",
        "        except:\n",
        "          continue\n",
        "      st.text(\"\")\n",
        "\n",
        "    new_df = pd.DataFrame.from_dict(new)\n",
        "    shapefile = 'https://data.cityofnewyork.us/api/geospatial/cpf4-rkhq?method=export&format=GeoJSON'\n",
        "    # Load the shapefile\n",
        "    df_nyc = gpd.GeoDataFrame.from_file(shapefile)\n",
        "    # Limit the data to only Manhattan neighborhoods \n",
        "    df_manhattan = df_nyc.query( \"boro_name =='Manhattan' \")\n",
        "    # Create a plot\n",
        "    #manhattan_plot = df_manhattan.plot(linewidth=0.5, color='White', edgecolor='Black', figsize=(15, 10))\n",
        "\n",
        "    base = df_manhattan.plot(linewidth=0.5, color='White', edgecolor='Black', figsize=(15, 10))\n",
        "\n",
        "    clean_mask = (new_df.latitude > 40) & (new_df.latitude < 41) & (new_df.longitude < -73) & (\n",
        "        new_df.longitude > -74.02)\n",
        "    cleandf = new_df[clean_mask]\n",
        "\n",
        "    z = cleandf.plot(kind='scatter', x='longitude', y='latitude', figsize=(15,10), ax = base, s=15,)\n",
        "\n",
        "    for i,txt in enumerate(cleandf.Name):\n",
        "      z.annotate(txt,(cleandf.longitude.iat[i]+0.00005,cleandf.latitude.iat[i]))\n",
        "    \n",
        "    st.pyplot(fig=plt)\n",
        "\n",
        "    cleanName = []\n",
        "    cleanLat = []\n",
        "    cleanLong = []\n",
        "    for i in range(len(new['Name'])):\n",
        "      if new['Name'][i] not in cleanName:\n",
        "        cleanName.append(new['Name'][i])\n",
        "        cleanLat.append(new['latitude'][i])\n",
        "        cleanLong.append(new['longitude'][i])\n",
        "    for i in range(len(cleanName)):\n",
        "      if cleanLat[i] == None :\n",
        "        st.text(\"Unfortunately we do not have a location for \" + cleanName[i])\n",
        "    st.text(\"\")\n",
        "\n",
        "    streamingFilter = streaming_df[\"Cluster\"] == findCategory(clusteredStreaming,maxMovieGenre)\n",
        "    userScoresStreaming = []\n",
        "    for j in range(len(streaming_df)):\n",
        "      userScore = 0\n",
        "      for i in User_Preferences[\"Movies\"]:\n",
        "        if (int(streaming_df.iloc[[j]][i].values[0])==1):\n",
        "          userScore += User_Preferences[\"Movies\"][i]\n",
        "      try:\n",
        "        userScore += streaming_df.iloc[[j]][\"Rating\"].values[0]\n",
        "      except:\n",
        "        userScore += 0\n",
        "      userScoresStreaming.append(userScore)\n",
        "    streaming_df[\"User Score\"] = userScoresStreaming\n",
        "    sortedStreamingCLuster = streaming_df[streamingFilter].sort_values(by=['User Score'], ascending=False)\n",
        "\n",
        "\n",
        "    st.text(\"If you would like to binge a show or movie at home here are some streaming recommendations.\")\n",
        "\n",
        "    for i in range (0, NumRecs):\n",
        "      try:\n",
        "        st.text(\"You can watch \" + sortedStreamingCLuster.iloc[[i]]['Title'].values[0] + \" on \" + sortedStreamingCLuster.iloc[[i]]['Platform'].values[0])\n",
        "      except:\n",
        "        continue"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbWSbZZFgB5N",
        "outputId": "113ef69c-c5f1-47fb-c269-15e3216e5d58"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "app.py\tnode_modules  nohup.out  package-lock.json  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Authenticate the NGROK\n",
        "!pip install -q pyngrok\n",
        "!ngrok authtoken 2JYqOFQMlVQMAO2f0LdhpJg108o_27RYbnQLjdBcUcK8PH2RF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISKC8Jm05HTT",
        "outputId": "204ff4a3-ebd8-49c8-a091-8671c46c1353"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0aTeyOb3l8NK"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To clear tunnels check and clear tunnels if necessary\n",
        "\n",
        "# tunnels = ngrok.get_tunnels()\n",
        "# tunnels\n",
        "# list(map(lambda k: ngrok.disconnect(k.public_url),tunnels))"
      ],
      "metadata": {
        "id": "rGrLiV6xQh_z"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup a tunnel to the streamlit port 8501\n",
        "public_url = ngrok.connect(8501)\n",
        "public_url\n",
        "\n",
        "# After running the app, click on the first link below to access the app"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Klz7g8gH017",
        "outputId": "e4814ddf-9c37-4a72-fd98-d070e92b1d56"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"http://8540-34-86-107-176.ngrok.io\" -> \"http://localhost:8501\">"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the application after ngrok tunnel is created\n",
        "#!streamlit run app.py &>/dev/null &\n",
        "!streamlit run /content/app.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fezzfNUsjW07",
        "outputId": "32f9b3d8-2f1d-43da-87db-6e30eee64f11"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.86.107.176:8501\u001b[0m\n",
            "\u001b[0m\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 1, iteration: 1/100, moves: 15, cost: 95.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 2, iteration: 1/100, moves: 13, cost: 76.0\n",
            "Run 2, iteration: 2/100, moves: 4, cost: 76.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 3, iteration: 1/100, moves: 9, cost: 79.0\n",
            "Run 3, iteration: 2/100, moves: 0, cost: 79.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 4, iteration: 1/100, moves: 11, cost: 96.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 5, iteration: 1/100, moves: 16, cost: 96.0\n",
            "Run 5, iteration: 2/100, moves: 2, cost: 96.0\n",
            "Best run was number 2\n",
            "/content/app.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[i] = foo[count]\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 1, iteration: 1/100, moves: 101, cost: 734.0\n",
            "Run 1, iteration: 2/100, moves: 0, cost: 734.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 2, iteration: 1/100, moves: 87, cost: 699.0\n",
            "Run 2, iteration: 2/100, moves: 24, cost: 699.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 3, iteration: 1/100, moves: 48, cost: 736.0\n",
            "Run 3, iteration: 2/100, moves: 6, cost: 735.0\n",
            "Run 3, iteration: 3/100, moves: 6, cost: 735.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 4, iteration: 1/100, moves: 78, cost: 733.0\n",
            "Run 4, iteration: 2/100, moves: 0, cost: 733.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 5, iteration: 1/100, moves: 233, cost: 771.0\n",
            "Run 5, iteration: 2/100, moves: 25, cost: 771.0\n",
            "Best run was number 2\n",
            "/usr/local/lib/python3.8/dist-packages/streamlit/runtime/scriptrunner/script_runner.py:565: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  exec(code, module.__dict__)\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 1, iteration: 1/100, moves: 17, cost: 81.0\n",
            "Run 1, iteration: 2/100, moves: 2, cost: 81.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 2, iteration: 1/100, moves: 8, cost: 95.0\n",
            "Run 2, iteration: 2/100, moves: 0, cost: 95.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 3, iteration: 1/100, moves: 7, cost: 102.0\n",
            "Run 3, iteration: 2/100, moves: 0, cost: 102.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 4, iteration: 1/100, moves: 18, cost: 89.0\n",
            "Run 4, iteration: 2/100, moves: 5, cost: 89.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 5, iteration: 1/100, moves: 19, cost: 73.0\n",
            "Run 5, iteration: 2/100, moves: 3, cost: 73.0\n",
            "Best run was number 5\n",
            "/content/app.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[i] = foo[count]\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 1, iteration: 1/100, moves: 60, cost: 735.0\n",
            "Run 1, iteration: 2/100, moves: 4, cost: 735.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 2, iteration: 1/100, moves: 30, cost: 791.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 3, iteration: 1/100, moves: 41, cost: 743.0\n",
            "Run 3, iteration: 2/100, moves: 5, cost: 743.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 4, iteration: 1/100, moves: 27, cost: 762.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 5, iteration: 1/100, moves: 46, cost: 760.0\n",
            "Run 5, iteration: 2/100, moves: 43, cost: 745.0\n",
            "Run 5, iteration: 3/100, moves: 1, cost: 745.0\n",
            "Best run was number 1\n",
            "/usr/local/lib/python3.8/dist-packages/streamlit/runtime/scriptrunner/script_runner.py:565: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  exec(code, module.__dict__)\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 1, iteration: 1/100, moves: 15, cost: 95.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 2, iteration: 1/100, moves: 10, cost: 98.0\n",
            "Run 2, iteration: 2/100, moves: 0, cost: 98.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 3, iteration: 1/100, moves: 10, cost: 83.0\n",
            "Run 3, iteration: 2/100, moves: 9, cost: 81.0\n",
            "Run 3, iteration: 3/100, moves: 0, cost: 81.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 4, iteration: 1/100, moves: 10, cost: 81.0\n",
            "Run 4, iteration: 2/100, moves: 1, cost: 81.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 5, iteration: 1/100, moves: 7, cost: 87.0\n",
            "Best run was number 3\n",
            "/content/app.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[i] = foo[count]\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 1, iteration: 1/100, moves: 61, cost: 737.0\n",
            "Run 1, iteration: 2/100, moves: 0, cost: 737.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 2, iteration: 1/100, moves: 39, cost: 721.0\n",
            "Run 2, iteration: 2/100, moves: 0, cost: 721.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 3, iteration: 1/100, moves: 57, cost: 751.0\n",
            "Run 3, iteration: 2/100, moves: 7, cost: 751.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 4, iteration: 1/100, moves: 51, cost: 750.0\n",
            "Run 4, iteration: 2/100, moves: 0, cost: 750.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 5, iteration: 1/100, moves: 70, cost: 716.0\n",
            "Best run was number 5\n",
            "/usr/local/lib/python3.8/dist-packages/streamlit/runtime/scriptrunner/script_runner.py:565: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  exec(code, module.__dict__)\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 1, iteration: 1/100, moves: 9, cost: 106.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 2, iteration: 1/100, moves: 17, cost: 88.0\n",
            "Run 2, iteration: 2/100, moves: 9, cost: 88.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 3, iteration: 1/100, moves: 12, cost: 84.0\n",
            "Run 3, iteration: 2/100, moves: 0, cost: 84.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 4, iteration: 1/100, moves: 7, cost: 105.0\n",
            "Run 4, iteration: 2/100, moves: 0, cost: 105.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 5, iteration: 1/100, moves: 9, cost: 93.0\n",
            "Run 5, iteration: 2/100, moves: 0, cost: 93.0\n",
            "Best run was number 3\n",
            "/content/app.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[i] = foo[count]\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 1, iteration: 1/100, moves: 29, cost: 760.0\n",
            "Run 1, iteration: 2/100, moves: 1, cost: 760.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 2, iteration: 1/100, moves: 73, cost: 741.0\n",
            "Run 2, iteration: 2/100, moves: 2, cost: 741.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 3, iteration: 1/100, moves: 94, cost: 778.0\n",
            "Run 3, iteration: 2/100, moves: 25, cost: 778.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 4, iteration: 1/100, moves: 59, cost: 788.0\n",
            "Run 4, iteration: 2/100, moves: 21, cost: 788.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 5, iteration: 1/100, moves: 55, cost: 744.0\n",
            "Run 5, iteration: 2/100, moves: 4, cost: 744.0\n",
            "Best run was number 2\n",
            "/usr/local/lib/python3.8/dist-packages/streamlit/runtime/scriptrunner/script_runner.py:565: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  exec(code, module.__dict__)\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 1, iteration: 1/100, moves: 6, cost: 89.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 2, iteration: 1/100, moves: 15, cost: 112.0\n",
            "Run 2, iteration: 2/100, moves: 3, cost: 112.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 3, iteration: 1/100, moves: 3, cost: 82.0\n",
            "Run 3, iteration: 2/100, moves: 0, cost: 82.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 4, iteration: 1/100, moves: 10, cost: 79.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 5, iteration: 1/100, moves: 21, cost: 95.0\n",
            "Run 5, iteration: 2/100, moves: 3, cost: 95.0\n",
            "Best run was number 4\n",
            "/content/app.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[i] = foo[count]\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 1, iteration: 1/100, moves: 42, cost: 753.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 2, iteration: 1/100, moves: 34, cost: 757.0\n",
            "Run 2, iteration: 2/100, moves: 7, cost: 757.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 3, iteration: 1/100, moves: 91, cost: 700.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 4, iteration: 1/100, moves: 46, cost: 743.0\n",
            "Run 4, iteration: 2/100, moves: 3, cost: 743.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 5, iteration: 1/100, moves: 42, cost: 775.0\n",
            "Best run was number 3\n",
            "/usr/local/lib/python3.8/dist-packages/streamlit/runtime/scriptrunner/script_runner.py:565: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  exec(code, module.__dict__)\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 1, iteration: 1/100, moves: 7, cost: 87.0\n",
            "Run 1, iteration: 2/100, moves: 0, cost: 87.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 2, iteration: 1/100, moves: 19, cost: 84.0\n",
            "Run 2, iteration: 2/100, moves: 5, cost: 84.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 3, iteration: 1/100, moves: 21, cost: 84.0\n",
            "Run 3, iteration: 2/100, moves: 5, cost: 84.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 4, iteration: 1/100, moves: 15, cost: 93.0\n",
            "Run 4, iteration: 2/100, moves: 0, cost: 93.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 5, iteration: 1/100, moves: 23, cost: 96.0\n",
            "Run 5, iteration: 2/100, moves: 3, cost: 96.0\n",
            "Best run was number 2\n",
            "/content/app.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[i] = foo[count]\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 1, iteration: 1/100, moves: 51, cost: 704.0\n",
            "Run 1, iteration: 2/100, moves: 1, cost: 704.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 2, iteration: 1/100, moves: 58, cost: 741.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 3, iteration: 1/100, moves: 48, cost: 797.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 4, iteration: 1/100, moves: 47, cost: 709.0\n",
            "Run 4, iteration: 2/100, moves: 4, cost: 709.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 5, iteration: 1/100, moves: 69, cost: 768.0\n",
            "Run 5, iteration: 2/100, moves: 2, cost: 768.0\n",
            "Best run was number 1\n",
            "/usr/local/lib/python3.8/dist-packages/streamlit/runtime/scriptrunner/script_runner.py:565: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  exec(code, module.__dict__)\n",
            "/content/app.py:171: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  theater_df[\"rating\"] = list_codes\n",
            "/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return super().drop(\n",
            "/content/app.py:173: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  theater_df['genres'] = theater_df['genres'].astype(str)\n",
            "/content/app.py:175: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 175 of the file /content/app.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  soup = BeautifulSoup(resp.text)\n",
            "/content/app.py:43: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[i] = foo[count]\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 1, iteration: 1/100, moves: 9, cost: 72.0\n",
            "Run 1, iteration: 2/100, moves: 0, cost: 72.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 2, iteration: 1/100, moves: 4, cost: 59.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 3, iteration: 1/100, moves: 5, cost: 70.0\n",
            "Run 3, iteration: 2/100, moves: 3, cost: 64.0\n",
            "Run 3, iteration: 3/100, moves: 0, cost: 64.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 4, iteration: 1/100, moves: 5, cost: 71.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 5, iteration: 1/100, moves: 12, cost: 64.0\n",
            "Run 5, iteration: 2/100, moves: 3, cost: 61.0\n",
            "Run 5, iteration: 3/100, moves: 1, cost: 61.0\n",
            "Best run was number 2\n",
            "/content/app.py:171: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  theater_df[\"rating\"] = list_codes\n",
            "/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return super().drop(\n",
            "/content/app.py:173: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  theater_df['genres'] = theater_df['genres'].astype(str)\n",
            "/content/app.py:175: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 175 of the file /content/app.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  soup = BeautifulSoup(resp.text)\n",
            "/content/app.py:43: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[i] = foo[count]\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 1, iteration: 1/100, moves: 12, cost: 72.0\n",
            "Run 1, iteration: 2/100, moves: 1, cost: 72.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 2, iteration: 1/100, moves: 5, cost: 79.0\n",
            "Run 2, iteration: 2/100, moves: 0, cost: 79.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 3, iteration: 1/100, moves: 18, cost: 52.0\n",
            "Run 3, iteration: 2/100, moves: 0, cost: 52.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 4, iteration: 1/100, moves: 6, cost: 67.0\n",
            "Run 4, iteration: 2/100, moves: 1, cost: 66.0\n",
            "Run 4, iteration: 3/100, moves: 0, cost: 66.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 5, iteration: 1/100, moves: 5, cost: 59.0\n",
            "Best run was number 3\n",
            "/content/app.py:171: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  theater_df[\"rating\"] = list_codes\n",
            "/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return super().drop(\n",
            "/content/app.py:173: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  theater_df['genres'] = theater_df['genres'].astype(str)\n",
            "/content/app.py:175: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 175 of the file /content/app.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  soup = BeautifulSoup(resp.text)\n",
            "/content/app.py:43: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[i] = foo[count]\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 1, iteration: 1/100, moves: 5, cost: 80.0\n",
            "Run 1, iteration: 2/100, moves: 3, cost: 73.0\n",
            "Run 1, iteration: 3/100, moves: 0, cost: 73.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 2, iteration: 1/100, moves: 11, cost: 65.0\n",
            "Run 2, iteration: 2/100, moves: 4, cost: 56.0\n",
            "Run 2, iteration: 3/100, moves: 0, cost: 56.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 3, iteration: 1/100, moves: 4, cost: 53.0\n",
            "Run 3, iteration: 2/100, moves: 0, cost: 53.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 4, iteration: 1/100, moves: 8, cost: 62.0\n",
            "Run 4, iteration: 2/100, moves: 0, cost: 62.0\n",
            "Init: initializing centroids\n",
            "Init: initializing clusters\n",
            "Starting iterations...\n",
            "Run 5, iteration: 1/100, moves: 4, cost: 76.0\n",
            "Best run was number 3\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "c7BIBbwynO_Q"
      },
      "outputs": [],
      "source": [
        "# If ngrok isn't working use this.\n",
        "#!npm install localtunnel\n",
        "\n",
        "#!streamlit run app.py & !npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1hSL-EHVsWmQ"
      },
      "execution_count": 14,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}